{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-the-IBES-PERMNO-link-file\" data-toc-modified-id=\"Load-the-IBES-PERMNO-link-file-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load the IBES PERMNO link file</a></span></li><li><span><a href=\"#Load-the-detail-IBES-history-file\" data-toc-modified-id=\"Load-the-detail-IBES-history-file-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load the detail IBES history file</a></span></li><li><span><a href=\"#Load-the-CRSP-file\" data-toc-modified-id=\"Load-the-CRSP-file-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load the CRSP file</a></span><ul class=\"toc-item\"><li><span><a href=\"#Calculate-the-earning-surprises\" data-toc-modified-id=\"Calculate-the-earning-surprises-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Calculate the earning surprises</a></span></li></ul></li><li><span><a href=\"#Load-Quarterly-Compustat\" data-toc-modified-id=\"Load-Quarterly-Compustat-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load Quarterly Compustat</a></span></li><li><span><a href=\"#Calculate-earnings-surprises\" data-toc-modified-id=\"Calculate-earnings-surprises-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Calculate earnings surprises</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-the-stock-price-5-days-before-the-earnings-announcement\" data-toc-modified-id=\"Get-the-stock-price-5-days-before-the-earnings-announcement-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Get the stock price 5 days before the earnings announcement</a></span></li></ul></li><li><span><a href=\"#Assign-S&amp;P-index\" data-toc-modified-id=\"Assign-S&amp;P-index-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Assign S&amp;P index</a></span></li><li><span><a href=\"#Save-output\" data-toc-modified-id=\"Save-output-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Save output</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** the procedures follow Livnat and Mendenhall (Journal of Accounting Research, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "from datetime import datetime\n",
    "bday_us = CustomBusinessDay(calendar=USFederalHolidayCalendar())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the IBES PERMNO link file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclink = pd.read_csv('../../Data/IBES/ibes_ticker_permno_link_file.csv')\n",
    "iclink = iclink[['TICKER', 'PERMNO', 'sdate', 'edate']]\n",
    "iclink = iclink[iclink['PERMNO'].notnull()]\n",
    "iclink['startdate'] = pd.to_datetime(iclink['sdate'], format='%d%b%Y')\n",
    "iclink['enddate'] = pd.to_datetime(iclink['edate'], format='%d%b%Y')\n",
    "iclink = iclink[['startdate', 'enddate', 'PERMNO', 'TICKER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the detail IBES history file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes = pd.read_csv('../../Data/IBES/IBES_Detail_History_1970_2019.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes = ibes[['TICKER', 'CUSIP', 'OFTIC', 'CNAME', 'ANNDATS',\n",
    "             'ESTIMATOR', 'ANALYS', 'PDF', 'VALUE',\n",
    "             'FPEDATS', 'REVDATS',  'ANNDATS_ACT', 'ANNTIMS_ACT', 'ACTUAL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove observations with no actual reported earnings\n",
    "ibes = ibes[ibes.ACTUAL.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes['FPEDATS'] = pd.to_datetime(ibes['FPEDATS'])\n",
    "ibes['REVDATS'] = pd.to_datetime(ibes['REVDATS'])\n",
    "ibes['ANNDATS'] = pd.to_datetime(ibes['ANNDATS'])\n",
    "\n",
    "# select the last estimate by broker-analyst\n",
    "ibes = ibes.sort_values(by=['TICKER', 'FPEDATS', 'ESTIMATOR',\n",
    "                            'ANALYS', 'ANNDATS', 'REVDATS'])\n",
    "ibes = ibes.groupby(['TICKER', 'FPEDATS',\n",
    "                     'ESTIMATOR', 'ANALYS']).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many estimates are reported on primary and diluted basis?\n",
    "ibes['p_count'] = np.where(ibes.PDF == 'P', 1, 0)\n",
    "ibes['d_count'] = np.where(ibes.PDF == 'D', 1, 0)\n",
    "p_count = ibes.groupby(['TICKER', 'FPEDATS'])['p_count'].sum().reset_index()\n",
    "d_count = ibes.groupby(['TICKER', 'FPEDATS'])['d_count'].sum().reset_index()\n",
    "ibes.drop(['p_count', 'd_count'], 1, inplace=True)\n",
    "ibes = pd.merge(ibes, p_count, on=['TICKER', 'FPEDATS'], how='left')\n",
    "ibes = pd.merge(ibes, d_count, on=['TICKER', 'FPEDATS'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes = ibes[ibes['ANNDATS_ACT'].notnull()]\n",
    "ibes['IBES_Timestamp'] = ibes['ANNDATS_ACT'].astype(str)+' '+ibes['ANNTIMS_ACT'].astype(str)\n",
    "ibes['IBES_Timestamp'] = pd.to_datetime(ibes['IBES_Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes['ANNDATS_ACT'] = pd.to_datetime(ibes['ANNDATS_ACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes['estdats1'] = np.where(ibes.ANNDATS.dt.weekday == 5,\n",
    "                            ibes.ANNDATS-bday_us, ibes.ANNDATS)\n",
    "ibes['estdats1'] = np.where(ibes.ANNDATS.dt.weekday == 6,\n",
    "                            ibes.ANNDATS-2*bday_us, ibes.estdats1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push days on monday if weekend\n",
    "ibes['repdats1'] = np.where(ibes.ANNDATS_ACT.dt.weekday == 5,\n",
    "                                 ibes.ANNDATS_ACT+2*bday_us,\n",
    "                                 ibes.ANNDATS_ACT)\n",
    "ibes['repdats1'] = np.where(ibes.ANNDATS_ACT.dt.weekday == 6,\n",
    "                                 ibes.ANNDATS_ACT+bday_us,\n",
    "                                 ibes.repdats1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes2 = pd.merge(ibes, iclink[['TICKER', 'PERMNO', 'startdate', 'enddate']],\n",
    "                 on=['TICKER'], how='left')\n",
    "ibes2['drop'] = np.where((ibes2.IBES_Timestamp < ibes2.startdate) |\n",
    "                         (ibes2.IBES_Timestamp > ibes2.enddate), 1, 0)\n",
    "ibes2 = ibes2[ibes2['drop'] != 1]\n",
    "ibes2.drop('drop', 1, inplace=True)\n",
    "ibes2 = ibes2[ibes2.FPEDATS < '2020-01-01']\n",
    "ibes2 = ibes2[ibes2.IBES_Timestamp.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the CRSP file\n",
    "daily stock file for security code 10,11 with exchange code 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp = pd.read_csv('../../Data/CRSP/crsp_dsf_1970_2019_sc10_11_ec123.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust = crsp[['date', 'CFACSHR', 'PERMNO']]\n",
    "adjust['date'] = pd.to_datetime(adjust.date)\n",
    "adjust['est_factor'] = adjust['CFACSHR']\n",
    "adjust['rep_factor'] = adjust['CFACSHR']\n",
    "adjust.drop('CFACSHR', 1, inplace=True)\n",
    "# keep PERMNO we want\n",
    "adjust = adjust[adjust.PERMNO.isin(ibes2.PERMNO.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if adjustment factors are not the same, adjust the estimate\n",
    "# to be on the same basis with the actual\n",
    "ibes2 = pd.merge(ibes2, adjust[['date', 'PERMNO', 'est_factor']], how='left',\n",
    "                 left_on=['PERMNO', 'estdats1'], right_on=['PERMNO', 'date'])\n",
    "\n",
    "ibes2 = pd.merge(ibes2, adjust[['date', 'PERMNO', 'rep_factor']], how='left',\n",
    "                 left_on=['PERMNO', 'repdats1'], right_on=['PERMNO', 'date'])\n",
    "ibes2.drop(['date_x', 'date_y'], 1, inplace=True)\n",
    "\n",
    "# adjust the analyst estimates\n",
    "ibes2['new_value'] = np.where((ibes2.est_factor != ibes2.rep_factor) &\n",
    "                              (ibes2.est_factor.notnull()) &\n",
    "                              (ibes2.rep_factor.notnull()),\n",
    "                              ibes2.rep_factor/ibes2.est_factor*ibes2.VALUE,\n",
    "                              ibes2.VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep analyst estimates in a 90 day window\n",
    "ibes2['time_window'] = ibes2.repdats1-ibes2.estdats1\n",
    "ibes2['time_window'] = ibes2['time_window'].astype('timedelta64[D]')\\\n",
    "                       .astype(int)\n",
    "ibes2 = ibes2[(ibes2.time_window > 0) & (ibes2.time_window <= 90)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the earning surprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst forecasts medians and averages\n",
    "medest = ibes2.groupby(['TICKER', 'FPEDATS'])[['new_value']].median()\\\n",
    "         .rename(columns={'new_value': 'medest'})\n",
    "meanest = ibes2.groupby(['TICKER', 'FPEDATS'])[['new_value']].mean()\\\n",
    "         .rename(columns={'new_value': 'meanest'})\n",
    "numest = ibes2.groupby(['TICKER', 'FPEDATS'])[['new_value']].count()\\\n",
    "         .rename(columns={'new_value': 'numest'})\n",
    "disp = ibes2.groupby(['TICKER', 'FPEDATS'])[['new_value']].std()\\\n",
    "       .rename(columns={'new_value': 'dispersion'})\n",
    "\n",
    "surp = pd.concat([medest, meanest, numest, disp], axis=1).reset_index()\n",
    "\n",
    "# Merge median estimates with ancillary information on permno,\n",
    "# actuals and report dates.\n",
    "# Determine whether most analysts are reporting estimates on primary\n",
    "# or diluted basis following Livnat and Mendenhall (2006)\n",
    "\n",
    "tmp = ibes2[['TICKER', 'CNAME', 'FPEDATS', 'CUSIP', 'p_count', 'd_count',\n",
    "             'PERMNO', 'ACTUAL', 'repdats1',\n",
    "             'ANNDATS_ACT', 'IBES_Timestamp']].drop_duplicates()\n",
    "surp = pd.merge(surp, tmp, how='left', on=['TICKER', 'FPEDATS'])\n",
    "surp['basis'] = np.where(surp.p_count <= surp.d_count, 'D', 'P')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Quarterly Compustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compustat is from the COMPUSTAT AND CRSP merged dataset\n",
    "compu = pd.read_csv('../../Data/Compustat/compustat_qtr_1961_2019.csv.gz')\n",
    "compu['scaled_net_income'] = compu['niq']/compu['saleq']\n",
    "\n",
    "compu = compu[(compu.fyr > 0) &\n",
    "              ((compu.saleq > 0) | (compu.atq > 0)) &\n",
    "              (compu.consol == 'C') & (compu.popsrc == 'D') &\n",
    "              (compu.indfmt == 'INDL') & (compu.datafmt == 'STD') &\n",
    "              (compu.datafqtr.notnull())]\n",
    "\n",
    "# Calculate the market cap\n",
    "compu['mcap'] = compu.cshoq*compu.prccq\n",
    "\n",
    "# Data filtering as in Livnat and Mendenhall (2006)\n",
    "compu = compu[(compu.rdq.notnull()) & (compu.prccq > 1) &\n",
    "              (compu.mcap > 5)]\n",
    "\n",
    "compu.drop(['consol', 'indfmt', 'datafmt', 'popsrc', 'curcdq'], 1, inplace=True)\n",
    "compu['datadate'] = pd.to_datetime(compu.datadate)\n",
    "\n",
    "# Create calendar date of fiscal period end in Compustat extract\n",
    "compu['day'] = 1\n",
    "compu['mth_adj'] = (-3*(4-compu.fqtr))\n",
    "compu['date_fyend'] = np.where(compu.fyr <= 5,\n",
    "                               pd.to_datetime(((compu.fyearq+1)*100+compu.fyr)*100+compu.day, format='%Y%m%d'),\n",
    "                               pd.to_datetime((compu.fyearq*100+compu.fyr)*100+compu.day, format='%Y%m%d'))\n",
    "compu['date_fyend'] = compu['date_fyend']+pd.offsets.MonthEnd(0)\n",
    "\n",
    "# This is slow to run ... I need to think of a faster processing\n",
    "compu['fqenddt'] = compu.apply(lambda x: x['date_fyend'] +\n",
    "                               pd.offsets.MonthEnd(x.mth_adj), axis=1)\n",
    "compu.drop(['day', 'mth_adj'], 1, inplace=True)\n",
    "\n",
    "# Calculate different actual and expected earnings from COMPUSTAT\n",
    "compu = compu.sort_values(by=['GVKEY', 'fqtr', 'fyearq'])\n",
    "for i in ['ajexq', 'epspxq', 'epsfxq', 'cshprq', 'cshfdq', 'spiq', 'scaled_net_income']:\n",
    "    compu['lag_'+i] = np.where((compu.fyearq-1 == compu.fyearq.shift()) &\n",
    "                               (compu.fqtr == compu.fqtr.shift()) &\n",
    "                               (compu.GVKEY == compu.GVKEY.shift()),\n",
    "                               compu[i].shift(), np.nan)\n",
    "\n",
    "compu['scaled_net_income_growth'] = (compu['scaled_net_income']-compu['lag_scaled_net_income'])/compu['scaled_net_income']\n",
    "# Merge GVKEY in the surprise dataframe\n",
    "cibeslnk = compu[['LPERMNO', 'GVKEY', 'fqenddt']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate earnings surprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign gvkey in the surp dataframe\n",
    "surp = pd.merge(surp, cibeslnk, how='left',\n",
    "                left_on=['PERMNO', 'FPEDATS'], right_on=['LPERMNO', 'fqenddt'])\n",
    "surp = surp[surp.GVKEY.notnull()]\n",
    "surp.drop('LPERMNO', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the actual and expected surprises as in LM (2006)\n",
    "# and accounting for exclusions of special items\n",
    "surp = pd.merge(surp, compu.drop('LPERMNO', 1),\n",
    "                on=['GVKEY', 'fqenddt'], how='left')\n",
    "\n",
    "surp['actual1'] = np.where(surp.basis == 'P',\n",
    "                           surp.epspxq/surp.ajexq,\n",
    "                           surp.epsfxq/surp.ajexq)\n",
    "surp['expected1'] = np.where(surp.basis == 'P',\n",
    "                             surp.lag_epspxq/surp.lag_ajexq,\n",
    "                             surp.lag_epsfxq/surp.lag_ajexq)\n",
    "\n",
    "surp['actual2'] = np.where(surp.basis == 'P',\n",
    "                           (surp.epspxq+0.65*surp.spiq/surp.cshprq)/surp.ajexq,\n",
    "                           (surp.epsfxq+0.65*surp.spiq/surp.cshfdq)/surp.ajexq)\n",
    "surp['expected2'] = np.where(surp.basis == 'P',\n",
    "                             (surp.lag_epspxq+0.65*surp.lag_spiq/surp.lag_cshprq)/surp.lag_ajexq,\n",
    "                             (surp.lag_epsfxq+0.65*surp.lag_spiq/surp.lag_cshfdq)/surp.lag_ajexq)\n",
    "\n",
    "surp['sue_rw'] = (surp.actual1-surp.expected1)/(surp.prccq/surp.ajexq)\n",
    "surp['sue_esi'] = (surp.actual2-surp.expected2)/(surp.prccq/surp.ajexq)\n",
    "surp['sue_for_med'] = (surp.ACTUAL-surp.medest)/(surp.prccq)\n",
    "surp['sue_for_mean'] = (surp.ACTUAL-surp.meanest)/(surp.prccq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: to further recalculate these earnigns surprises with forecast\n",
    "# using stock price 5 days before EA.\n",
    "\n",
    "# Apply the LM filters and earnings report dates in Compustat\n",
    "# and in IBES (if available) should not differ by more than one calendar day\n",
    "surp = surp[(surp.rdq.notnull()) & (surp.prccq > 1) & (surp.mcap > 5)]\n",
    "surp['rdq'] = pd.to_datetime(surp.rdq)\n",
    "surp['day_diff'] = surp.rdq-surp.repdats1\n",
    "surp['day_diff'] = surp['day_diff'].astype('timedelta64[D]')\n",
    "surp = surp[surp['day_diff'].between(-1, 1)]\n",
    "\n",
    "surp['ADJ_ACTUAL'] = surp['actual1']\n",
    "surp['adj_expected_earnings'] = surp['expected1']\n",
    "\n",
    "surp = surp[['TICKER', 'PERMNO', 'GVKEY', 'CNAME', 'fyr', 'fyearq', 'fqenddt',\n",
    "             'repdats1', 'ANNDATS_ACT', 'IBES_Timestamp', 'rdq', 'adj_expected_earnings',\n",
    "             'sue_rw', 'sue_esi', 'sue_for_med', 'sue_for_mean', 'basis', 'ACTUAL', 'ADJ_ACTUAL',\n",
    "             'medest', 'numest', 'meanest', 'dispersion', 'prccq', 'mcap',\n",
    "             'ggroup', 'gind', 'gsector', 'gsubind']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the stock price 5 days before the earnings announcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crsp = pd.read_csv('../Data/crsp_2007_2018.csv.gz')\n",
    "crsp.drop(['EXCHCD', 'SHRCD'], 1, inplace=True)\n",
    "\n",
    "crsp['date'] = pd.to_datetime(crsp['date'])\n",
    "crsp['PRC'] = np.abs(crsp['PRC'])\n",
    "\n",
    "crsp_ = crsp[['date', 'PRC', 'PERMNO']]\n",
    "crsp_ = crsp_.sort_values(by=['PERMNO', 'date'])\n",
    "crsp.index = pd.to_datetime(crsp['date'])\n",
    "\n",
    "crsp_['PRC_s'] = crsp_.groupby('PERMNO')['PRC'].shift(5)  # shift prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same procedures as in Hirsleifer paper on drift and attention\n",
    "surp['ANNDATS_ACT'] = np.where((surp.rdq == surp.ANNDATS_ACT) &\n",
    "                                 (surp.rdq.dt.year<1990),\n",
    "                                 surp.ANNDATS_ACT - pd.offsets.Day(1),\n",
    "                                 surp.ANNDATS_ACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) If after 1990, COMPU date is before IBES date, take the compu date\n",
    "surp['day_diff'] = surp.rdq-surp.ANNDATS_ACT\n",
    "surp['day_diff'] = surp['day_diff'].astype('timedelta64[D]')\n",
    "\n",
    "surp['ANNDATS_ACT'] = np.where(surp.day_diff == -1 &\n",
    "                                 (surp.rdq.dt.year>1990),\n",
    "                                 surp.rdq, surp.ANNDATS_ACT)\n",
    "surp.drop('day_diff', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_days = pd.DataFrame(index=(np.sort(list(crsp['date'].dt.date.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (3) Create an IBES Adjusted date to get the first trading day following the\n",
    "# news if the EA is on a holiday or weekend.\n",
    "repdats1_adj = []\n",
    "for x in surp['ANNDATS_ACT'].dt.date:\n",
    "    if x in trading_days:\n",
    "        repdats1_adj.append(x)\n",
    "    else:\n",
    "        repdats1_adj.append(trading_days.loc[x:].index.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp['IBES_Act_Date_Adj'] = pd.to_datetime(repdats1_adj)\n",
    "# IBES_Act_Date_Adj will be the right day as day 0 for EA days\n",
    "\n",
    "surp = surp.drop_duplicates()\n",
    "surp = pd.merge(surp, crsp_, how='left',\n",
    "                left_on=['PERMNO', 'IBES_Act_Date_Adj'],\n",
    "                right_on=['PERMNO', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if PRC_s not available in CRSP, because share code != 10 or 11 (e.g., ADR)\n",
    "# drop these firms\n",
    "surp = surp[surp.PRC_s.notnull()]\n",
    "\n",
    "surp['SUE_Med'] = (surp.ACTUAL-surp.medest)/(surp.PRC_s)\n",
    "surp['SUE_Mean'] = (surp.ACTUAL-surp.meanest)/(surp.PRC_s)\n",
    "\n",
    "# Similarly to LM (2006) keep obs. where sue_rw is not null\n",
    "surp = surp[surp.sue_rw.notnull()]\n",
    "surp = surp[surp.PERMNO.notnull()]\n",
    "\n",
    "# cases where same PERMNO two different tickers, remove one obs (total 52)\n",
    "surp['rem'] = np.where((surp.PERMNO == surp.PERMNO.shift()) &\n",
    "                       (surp.repdats1 == surp.repdats1.shift()) &\n",
    "                       (surp.TICKER != surp.TICKER.shift()), 1, 0)\n",
    "\n",
    "# remove possible case of duplicates where duplicate has the exact same info\n",
    "# but the sue_rw is (erroneously) equals zero\n",
    "surp['abs_sue'] = np.abs(surp.sue_rw)\n",
    "surp = surp.sort_values(by=['PERMNO', 'repdats1', 'fqenddt', 'abs_sue'])\n",
    "surp['rem'] = np.where((surp.PERMNO == surp.PERMNO.shift(-1)) &\n",
    "                       (surp.repdats1 == surp.repdats1.shift(-1)) &\n",
    "                       (surp.abs_sue == 0), 1, surp.rem)\n",
    "surp = surp[surp.rem == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In very few cases, a rdq in COMPU will have 2 entries\n",
    "# from two different quarters. Keep the earnings surprise that matches\n",
    "# the correct quarter and the quarter date in rdq\n",
    "\n",
    "surp['rem'] = np.where((surp.PERMNO == surp.PERMNO.shift(-1)) &\n",
    "                       (surp.rdq == surp.rdq.shift(-1)), 1, 0)\n",
    "surp = surp[surp.rem == 0]\n",
    "\n",
    "# one case only\n",
    "surp['rem'] = np.where((surp.IBES_Act_Date_Adj ==\n",
    "                        surp.IBES_Act_Date_Adj.shift(-1)) &\n",
    "                       (surp.fqenddt != surp.fqenddt.shift(-1)) &\n",
    "                       (surp.PERMNO == surp.PERMNO.shift(-1)), 1, 0)  \n",
    "surp = surp[surp.rem == 0]\n",
    "surp.drop(['rem', 'abs_sue', 'date'], 1, inplace=True)\n",
    "\n",
    "# Calculate some measure of price to earnings ratio.\n",
    "surp['prc_exp_eps'] = surp.PRC_s/surp.medest\n",
    "surp['prccq_exp_eps'] = surp.prccq/surp.medest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp['PERMNO'] = surp['PERMNO'].astype(int)\n",
    "surp['GVKEY'] = surp['GVKEY'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp.rename(columns={'TICKER':'IBES_TICKER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp['Year'] = surp['IBES_Timestamp'].dt.year\n",
    "surp['Quarter'] = surp['IBES_Timestamp'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = surp[['PERMNO', 'IBES_TICKER', 'GVKEY', 'CNAME', 'ANNDATS_ACT', 'IBES_Timestamp', 'IBES_Act_Date_Adj',\n",
    "             'Year', 'Quarter', 'rdq',\n",
    "             \"SUE_Med\", 'sue_rw', 'ACTUAL', 'ADJ_ACTUAL', 'mcap', 'numest', 'dispersion',\n",
    "             'ggroup', 'gind', 'gsector', 'gsubind', 'medest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp['date'] = pd.to_datetime(surp['IBES_Timestamp'].dt.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign S&P index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the SP index constituants\n",
    "def assignSPIndex(filedir, surp_, index):\n",
    "    df = pd.read_csv(filedir)\n",
    "    df = df[['gvkey', 'from', 'thru']].rename(columns={'gvkey':'GVKEY'})\n",
    "    df['GVKEY'] = df['GVKEY'].astype(int)\n",
    "    df['date'] = pd.to_datetime(df['from'])\n",
    "    df['thru'].fillna('2019-12-31', inplace=True)\n",
    "    df['thru'] = pd.to_datetime(df['thru'])\n",
    "    df[index] = 1\n",
    "    df = df.sort_values(by=['date', 'GVKEY'])\n",
    "    \n",
    "    surp_ = surp_.sort_values(by=['date', 'GVKEY'])\n",
    "    surp_ = pd.merge_asof(surp_, df, on='date', by='GVKEY')\n",
    "    surp_[index] = np.where(surp_.date>surp_['thru'], 0, surp_[index])  # remove firms kicked out of SP500\n",
    "    surp_ = surp_.sort_values(by=['date', 'PERMNO'])\n",
    "    surp_ = surp_.drop(['from', 'thru'], 1)\n",
    "    return surp_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = assignSPIndex('../../Data/Compustat/sp500.csv', surp, 'sp500')\n",
    "surp = assignSPIndex('../../Data/Compustat/sp400.csv', surp, 'sp400')\n",
    "surp = assignSPIndex('../../Data/Compustat/sp600.csv', surp, 'sp600')\n",
    "surp = assignSPIndex('../../Data/Compustat/sp1500.csv', surp, 'sp1500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['sp500', 'sp400', 'sp600', 'sp1500']:\n",
    "    surp[i].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = surp.drop_duplicates(subset=['PERMNO', 'IBES_Timestamp'], keep='first') # this kills one obs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp.to_hdf('../../Data/IBES/Earnings_Announcements_and_Surprises.h5', key='panel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
